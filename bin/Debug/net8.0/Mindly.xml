<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Mindly</name>
    </assembly>
    <members>
        <member name="T:Mindly.Migrations.InitialCreate">
            <inheritdoc />
        </member>
        <member name="M:Mindly.Migrations.InitialCreate.Up(Microsoft.EntityFrameworkCore.Migrations.MigrationBuilder)">
            <inheritdoc />
        </member>
        <member name="M:Mindly.Migrations.InitialCreate.Down(Microsoft.EntityFrameworkCore.Migrations.MigrationBuilder)">
            <inheritdoc />
        </member>
        <member name="M:Mindly.Migrations.InitialCreate.BuildTargetModel(Microsoft.EntityFrameworkCore.ModelBuilder)">
            <inheritdoc />
        </member>
        <member name="M:AutoconhecimentoController.Post(AutoconhecimentoController.AutoconhecimentoRequest)">
             <summary>
             Avalia sinais de bem-estar emocional com base em 8 indicadores.
             </summary>
             <remarks>
             A avaliação soma 1 ponto para cada item marcado como verdadeiro:
             cansaço, dificuldade de sono, ansiedade, dificuldade de concentração, tristeza,
             perda de interesse, irritação e pensamentos negativos.
            
             Faixas de resultado:
             - 0 a 2: equilíbrio emocional, sugestões leves de autocuidado.
             - 3 a 5: atenção a sinais de alerta, recomendações de rotina e relaxamento.
             - 6 a 8: alerta importante, recomendação de procurar acompanhamento profissional.
             </remarks>
             <response code="200">Retorna o resultado textual e uma lista de dicas</response>
        </member>
        <member name="M:EmocoesController.RegistrarEmocao(EmocaoRequest)">
            <summary>
            Detecta risco e tópicos emocionais a partir de um texto.
            </summary>
            <remarks>
            Este endpoint envia o texto para o serviço externo (/detect) e retorna um indicador de alerta,
            palavras de alerta detectadas, tópicos identificados e uma pontuação de risco. Também marcamos
            alerta localmente se palavras explícitas de violência forem encontradas.
            </remarks>
            <param name="request">Texto a ser avaliado</param>
            <response code="200">Retorna status de sucesso, alerta consolidado e o objeto de detecção</response>
        </member>
    </members>
</doc>
